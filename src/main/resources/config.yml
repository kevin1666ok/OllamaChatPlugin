# 配置 Ollama API 相关信息
ollama:
  # 当前使用的 Ollama 模型
  current_model: llama2:7b
  # 可供选择的 Ollama 模型列表，可根据实际情况添加或修改
  available_models:
    - llama2:7b
    - llama2:13b
    - mistral:7b
  # Ollama 服务的使用模式，可选值为 "built-in"（内置）或 "standalone"（独立）
  mode: built-in
  # 内置 Ollama 服务的 API 请求地址，通常为本地地址
  built_in_url: http://localhost:11434/api/generate
  # 独立 Ollama 服务的 API 请求地址，用于连接外部的 Ollama 服务
  standalone_url: http://external-ollama-server:11434/api/generate

# 配置新 API 相关信息
new-api:
  # 当前使用的新 API 模型
  model: default-model
  # 新 API 的请求地址
  url: https://example.com/api/generate
  # 访问新 API 所需的密钥，需要替换为实际的密钥
  key: your_api_key_here

# 按行输出时每行之间的延迟时间（游戏刻），可调整以改变打字效果的速度
line-delay: 60

# 可选择使用的 API 类型，可选值为 "ollama" 或 "new-api"，决定使用哪个 API 进行交互
api-type: ollama